<!DOCTYPE html>
<html lang="en">
<head>
        <title>Alex Minnaar's Blog - Machine Learning, Data Science and Software Engineering - Natural-Language-Processing</title>
        <meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link rel="shortcut icon" href="http://launchyard.com/images/favicon.png"/>
        <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie.css"/>
                <script src="/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie6.css"/><![endif]-->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js" type="text/javascript"></script>


</head>

<body id="index" class="home">
	
  <!--      <header id="banner" class="body">
                <h1><a href="/"><img src="http://www.launchyard.com/images/logo.png" /></a></h1>
        </header> -->
<!-- /#banner -->
	      <div class="LaunchyardDetail"><p><a href="/"></a>
<a class="title" href="http://alexminnaar.github.io/">Alex Minnaar</a>
<br/>
Machine Learning at University College London. Natural language processing at VerticalScope.
<br/>
<br/>
<a href="mailto:minnaaralex@gmail.com">Email</a><br />
<a href="https://github.com/alexminnaar">Github</a><br/>
<a href="https://ca.linkedin.com/pub/alex-minnaar/56/a23/853">LinkedIn</a><br/>
</p>


<div id="recent_posts">
			<h3>Categories</h3>
			<div align="left">
			<ul>
				<li><a href="/tag/nlp.html">NLP & Topic Models</a></li>
				<li><a href="/tag/supervised-learning.html">Supervised Learning</a></li>
				<li><a href="/tag/bayesian-inference.html">Bayesian Inference</a></li>
				<li><a href="/tag/kaggle-competitions.html">Kaggle Competitions</a></li>
				<li><a href="/tag/software-engineering.html">Software Engineering</a></li>
			</ul>
			</div>
              <h3>Recent Posts</h3>
                <a href="building-a-shoutbox-app-with-cassandra-and-nodejs.html">Building a Shoutbox App with Cassandra and Node.js</a><br /><br />
                <a href="/building-a-distributed-binary-search-tree-with-akka.html">Building a Distributed Binary Search Tree with Akka</a><br /><br />
                <a href="/introduction-to-the-multithreading-problem-and-the-akka-actor-solution.html">Introduction to the Multithreading Problem and the Akka Actor Solution  </a><br /><br />
                <a href="/scalaner-a-scala-wrapper-for-the-stanford-ner-tool-with-some-added-features.html">ScalaNER: A Scala Wrapper for the Stanford NER Tool with Some Added Features  </a><br /><br />
                <a href="/online-latent-dirichlet-allocation-the-best-option-for-topic-modeling-with-large-data-sets.html">Online Latent Dirichlet Allocation - The Best Option for Topic Modeling with Large Data Sets  </a><br /><br />
                <a href="/latent-dirichlet-allocation-in-scala-part-ii-the-code.html">Latent Dirichlet Allocation in Scala Part II - The Code </a><br /><br />
          </div>

</div>

        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/building-a-named-entity-recognition-system-tips-and-best-practices.html">Building a Named Entity Recognition System: Tips and Best Practices</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2014-11-11T00:00:00+01:00">
          on&nbsp;Tue 11 November 2014
        </li>

	</ul>
<p>Category: <a href="/tag/nlp.html">   NLP</a></p>
</div><!-- /.post-info -->
                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/scalaner-a-scala-wrapper-for-the-stanford-ner-tool-with-some-added-features.html">ScalaNER: A Scala Wrapper for the Stanford NER Tool with Some Added Features</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2014-11-11T00:00:00+01:00">
          on&nbsp;Tue 11 November 2014
        </li>

	</ul>
<p>Category: <a href="/tag/nlp.html">   NLP</a><a href="/tag/software-engineering.html">   Software Engineering</a></p>
</div><!-- /.post-info --><p>The <a href="http://nlp.stanford.edu/software/CRF-NER.shtml">Stanford NER (named entity recognizer) tool</a> is a widely-used, general purpose named entity recognition tool that Stanford has made available as part of its CoreNLP Java library.  It performs named entity recognition via a CRF-based sequence model which has been known to give near state-of-the-art performance results which makes it a popular choice for open-source NER tools.</p>
<p>Having said that, I have used this tool in the past and I was left wanting more functionality.  From its <a href="http://nlp.stanford.edu/software/crf-faq.shtml">FAQ section</a>, you can see that most of its functionality (i.e. training and testing a NER model) is designed to be performed using the command line.  But what if you want to use a pre-trained NER model as part of a real-time text processing pipeline?  For example, you are processing a string of text and you want to apply your NER model to the text and then do something with the tokens corresponding to classified named entities.  There is no clear way to do this with the Stanford NER tool.</p>
<p>I have also found that the Stanford NER tool is lacking in its model validation functionality.  Just like any classification model, I want to be able to perform cross-validation tests on my training data so that I can be confident in its generalized performance.  Again, there is no clear way of doing this.  You can test your model on a test set and obtain the precision, recall and F1 values but unfortunately these values are just shown in standard output and there is no way to persist them.  Consequently, if you wanted to perform 50-fold cross-validation on your dataset you would have to visually read each of the 50 sets of performance metrics off the screen and then manually average them to get your desired result (or export standard output and parse it).  Obviously no one wants to do this.</p>
<p><a href="https://github.com/alexminnaar/ScalaNER">ScalaNER</a> attempts to solve these problems by offering the following additional functionality to the Stanford NER tool.</p>
<ul>
<li>Programmatically apply a pre-trained NER model to a string of text and output the labelled result.</li>
<li>Programmatically train an NER model.</li>
<li>Easy model validation.  Specifically cross-validation.</li>
</ul>
<h2>ScalaNER Demo</h2>
<p>The following code samples demonstrate this new functionality.  First of all, it should be noted that the training data sets must be in the same format that the Stanford NER tool accepts.  That is, each line must contain a tab-separated token/label pair.  Entity labels can be any string but non-entity labels must be "O".  For example, training data for a person name entity might look like</p>
<div class="highlight"><pre>The    O
US    O
president    O
is    O
Barrack    NAME
Obama    NAME
</pre></div>


<p>where named entities are labelled as "NAME" and non-entity tokens are labelled as "O".</p>
<h3>Train an NER Model</h3>
<p>First we will demonstrate how to train a NER model given a training dataset in the format explained above.  The code is very simple - in fact it is only one line.  It uses a Scala object called <code>NERModel</code>.  To train an NER model you simply call this object's <code>trainClassifier</code> method which takes two arguments, the location of the training data file (it must be a text file) and the filename and location where the the trained NER model will be saved.</p>
<div class="highlight"><pre><span class="nc">NERModel</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span><span class="s">&quot;my/data/location.txt&quot;</span><span class="o">,</span> <span class="s">&quot;save/my/model/here.ser.gz&quot;</span><span class="o">)</span>
</pre></div>


<h3>Apply an NER Model</h3>
<p>Then once you have trained your NER model you will probably want to apply this model to some new text.  To do this we use the <code>ApplyModel</code> class which takes the location of the trained model as a constructor.  Once this class has been instantiated, we call its <code>runNER</code> method which takes a string as an input argument.  This input string is the text from which you want to extract the named entities.  The result is an indexed sequence of <code>LabeledToken</code> objects which contain a token field and a label field.  The token fields contain the tokens in the input string and the label fields contain the named entities that the tokens have been assigned to.</p>
<div class="highlight"><pre><span class="k">val</span> <span class="n">classifier</span><span class="k">=new</span> <span class="nc">ApplyModel</span><span class="o">(</span><span class="s">&quot;my/pretrained/model.ser.gz&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">results</span><span class="k">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">runNER</span><span class="o">(</span><span class="s">&quot;Find named entities in this new sentence.&quot;</span><span class="o">)</span>
</pre></div>


<h3>Performing Cross-Validation on an NER Model</h3>
<p>To perform cross-validation we use the CrossValidation class which takes the number of folds and training data location as constructors.  Then we call the <code>runCrossValidation</code> method with an input parameter that is the location of the directory where the training and validation sets will be written.  The result is a vector whose elements correspond to the number of folds.  Each element is a map whose keys represent the unique entity types in that fold and values represent the precision, recall and F1-score of the corresponding entity type.</p>
<div class="highlight"><pre><span class="k">val</span> <span class="n">testInstance</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CrossValidation</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;location/of/training/data.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">xvalResults</span><span class="k">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">runCrossValidation</span><span class="o">(</span><span class="s">&quot;directory/to/write/xvalidation/data/&quot;</span><span class="o">)</span>
</pre></div>


<p>Next let's look at a real-world example.</p>
<h2>Example: Identifying Protein Names</h2>
<p>Suppose that you wanted to train an NER model to identify protein named in bio-medical literature.  We will use the BioNLP dataset that has already been transformed into the correct Stanford NER format which can be found in the <a href="https://github.com/alexminnaar/ScalaNER/tree/master/data">ScalaNER github repo</a>.</p>
<p>First let's try training an NER model with this data and running it on a sample string of text to determine if it contains any protein names.</p>
<div class="highlight"><pre><span class="nc">NERModel</span><span class="o">.</span><span class="n">trainClassifier</span><span class="o">(</span><span class="s">&quot;data/bionlp.txt&quot;</span><span class="o">,</span> <span class="s">&quot;/bioNlpModel.ser.gz&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">classifier</span><span class="k">=new</span> <span class="nc">ApplyModel</span><span class="o">(</span><span class="s">&quot;/bioNlpModel.ser.gz&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">results</span><span class="k">=</span><span class="n">classifier</span><span class="o">.</span><span class="n">runNER</span><span class="o">(</span><span class="s">&quot;Leukotriene B4 stimulates c-fos and c-jun gene transcription and AP-1 binding activity in human monocytes.&quot;</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="n">results</span><span class="o">)</span>
</pre></div>


<p>Which gives the following output</p>
<p><code>Vector(LabeledToken(Leukotriene,O), LabeledToken(B4,O), LabeledToken(stimulates,O), LabeledToken(c-fos,protein), LabeledToken(and,O), LabeledToken(c-jun,protein), LabeledToken(gene,O), LabeledToken(transcription,O), LabeledToken(and,O), LabeledToken(AP-1,O), LabeledToken(binding,O), LabeledToken(activity,O), LabeledToken(in,O), LabeledToken(human,O), LabeledToken(monocytes,O), LabeledToken(.,O))</code></p>
<p>As you can see, the trained model assigns the correct <em>protein</em> label to the tokens "c-fos" and "c-jun" and all other tokens are assigned the <em>O</em> label indicating that they are not named entities.</p>
<p>Next, let's perform 5-fold cross-validation on the entire dataset to get a good idea of its generalized performance.  This can be done in the following code where we specify the folder "data/xval" to be location where the 5 training and validation sets will be written.</p>
<div class="highlight"><pre><span class="k">val</span> <span class="n">cv</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">CrossValidation</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="s">&quot;data/bionlp.txt&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">testResults</span> <span class="k">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">runCrossValidation</span><span class="o">(</span><span class="s">&quot;data/xval&quot;</span><span class="o">)</span>

<span class="n">println</span><span class="o">(</span><span class="n">testResults</span><span class="o">)</span>
</pre></div>


<p>Which gives the following output</p>
<p><code>Vector(Map(protein -&gt; Performance(0.680461329715061,0.9862340216322517,0.8052990766760337), O -&gt; Performance(0.999634483838964,0.9878479836941098,0.9937062846316554)), Map(O -&gt; Performance(0.9991162403826159,0.9858425237240318,0.9924350003872866), protein -&gt; Performance(0.5766871165644172,0.9567430025445293,0.7196172248803828)), Map(O -&gt; Performance(0.9986442092089483,0.9858183409260546,0.9921898273472612), protein -&gt; Performance(0.6125175808720112,0.9436619718309859,0.7428571428571428)), Map(O -&gt; Performance(0.9994266652767643,0.9878419452887538,0.9936005389019872), protein -&gt; Performance(0.6638176638176638,0.9769392033542977,0.7905004240882104)), Map(O -&gt; Performance(0.9988831168831169,0.9877484974572354,0.9932846036624738), protein -&gt; Performance(0.6261755485893417,0.9489311163895487,0.7544853635505192)))</code></p>
<p>The above output shows the precision, recall and F1-scores for each entity type (in this case protein and O) and each of the 5 folds.  So the F1-scores associated with identifying <em>protein</em> named entities are 0.8052, 0.7196, 0.7428, 0.7905, and 0.7544 for an average F1-score of 0.7625.</p>
<h2>References</h2>
<ul>
<li><a href="http://nlp.stanford.edu/software/CRF-NER.shtml">Stanford Named Entity Recognizer</a></li>
<li><a href="https://github.com/alexminnaar/ScalaNER">ScalaNER Github Repo</a></li>
</ul>
                    </article>
 
<div class="paginator">
    <div class="navButton">Page 1 / 1</div>
</div>
                </div>
            </aside><!-- /#featured -->
            
        
        <section id="extras" >
       
        
        </section><!-- /#extras -->
	
        <footer id="contentinfo" >
                <address id="about" class="vcard ">
                Proudly powered by <a href="http://getpelican.com/" target="_blank">Pelican</a>, which takes
                great advantage of <a href="http://python.org" target="_blank">Python</a>. &copy; <a class="url fn" href="http://launchyard.com">LaunchYard</a>
		
                </address><!-- /#about -->
		

                
        </footer><!-- /#contentinfo -->

<script type="text/javascript">
    var disqus_shortname = 'alexminnaar';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>