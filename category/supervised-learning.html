<!DOCTYPE html>
<html lang="en">
<head>
        <title>Alex Minnaar's Blog - Machine Learning, Data Science and Software Engineering - Supervised-Learning</title>
        <meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link rel="shortcut icon" href="http://launchyard.com/images/favicon.png"/>
        <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie.css"/>
                <script src="/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie6.css"/><![endif]-->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js" type="text/javascript"></script>


</head>

<body id="index" class="home">
	
  <!--      <header id="banner" class="body">
                <h1><a href="/"><img src="http://www.launchyard.com/images/logo.png" /></a></h1>
        </header> -->
<!-- /#banner -->
	      <div class="LaunchyardDetail"><p><a href="/"></a>
<a class="title" href="http://alexminnaar.github.io/">Alex Minnaar</a>
<br/>
Machine Learning at University College London. Natural language processing at VerticalScope.
<br/>
<br/>
<a href="mailto:minnaaralex@gmail.com">Email</a><br />
<a href="https://github.com/alexminnaar">Github</a><br/>
<a href="https://ca.linkedin.com/pub/alex-minnaar/56/a23/853">LinkedIn</a><br/>
</p>


<div id="recent_posts">
			<h3>Categories</h3>
			<div align="left">
			<ul>
				<li><a href="/tag/nlp.html">NLP & Topic Models</a></li>
				<li><a href="/tag/supervised-learning.html">Supervised Learning</a></li>
				<li><a href="/tag/bayesian-inference.html">Bayesian Inference</a></li>
				<li><a href="/tag/kaggle-competitions.html">Kaggle Competitions</a></li>
				<li><a href="/tag/software-engineering.html">Software Engineering</a></li>
			</ul>
			</div>
              <h3>Recent Posts</h3>
                <a href="word2vec-tutorial-part-ii-the-continuous-bag-of-words-model.html">Word2Vec Tutorial Part II: The Continuous Bag-of-Words Model</a><br /><br />
                <a href="word2vec-tutorial-part-i-the-skip-gram-model.html">Word2Vec Tutorial Part I: The Skip-Gram Model</a><br /><br />
                <a href="distributed-online-latent-dirichlet-allocation-with-apache-spark.html">Distributed Online Latent Dirichlet Allocation with Apache Spark</a><br /><br />
                <a href="deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html">Deep Learning Basics: Neural Networks, Backpropagation and Stochastic Gradient Descent</a><br /><br />
                <a href="building-a-shoutbox-app-with-cassandra-and-nodejs.html">Building a Shoutbox App with Cassandra and Node.js</a><br /><br />
                <a href="/building-a-distributed-binary-search-tree-with-akka.html">Building a Distributed Binary Search Tree with Akka</a><br /><br />
                <a href="/introduction-to-the-multithreading-problem-and-the-akka-actor-solution.html">Introduction to the Multithreading Problem and the Akka Actor Solution  </a><br /><br />
                <a href="/scalaner-a-scala-wrapper-for-the-stanford-ner-tool-with-some-added-features.html">ScalaNER: A Scala Wrapper for the Stanford NER Tool with Some Added Features  </a><br /><br />
                <a href="/online-latent-dirichlet-allocation-the-best-option-for-topic-modeling-with-large-data-sets.html">Online Latent Dirichlet Allocation - The Best Option for Topic Modeling with Large Data Sets  </a><br /><br />
                <a href="/latent-dirichlet-allocation-in-scala-part-ii-the-code.html">Latent Dirichlet Allocation in Scala Part II - The Code </a><br /><br />
          </div>

</div>

        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/word2vec-tutorial-part-ii-the-continuous-bag-of-words-model.html">Word2Vec Tutorial Part II: The Continuous Bag-of-Words Model</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2015-05-18T00:00:00+02:00">
          on&nbsp;Mon 18 May 2015
        </li>

	</ul>
<p>Category: <a href="/tag/nlp.html">   NLP</a><a href="/tag/supervised-learning.html">   Supervised Learning</a></p>
</div><!-- /.post-info --><p>In the <a href="http://alexminnaar.com/word2vec-tutorial-part-i-the-skip-gram-model.html">previous post</a> the concept of word vectors was explained as was the derivation of the <em>skip-gram</em> model.  In this post we will explore the other <em>Word2Vec</em> model - the <em>continuous bag-of-words</em> (CBOW) model.  If you understand the <em>skip-gram</em> model then the <em>CBOW</em> model should be quite straight-forward because in many ways they are mirror images of each other.  For instance, if you look at the model diagram</p>
<p><img alt="skip-gram model" src="images/cbow.png" /> </p>
<p>it looks like the <em>skip-gram</em> model with the inputs and outputs reversed.  The input layer consists of the <em>one-hot</em> encoded input context words <span class="math">\(\{\mathbf{x_1},...,\mathbf{x_C}\}\)</span> for a word window of size <span class="math">\(C\)</span> and vocabulary of size <span class="math">\(V\)</span>.  The hidden layer is an N-dimensional vector <span class="math">\(\mathbf{h}\)</span>.  Finally, the output layer is output word <span class="math">\(\mathbf{y}\)</span> in the training example which is also <em>one-hot</em> encoded.  The <em>one-hot</em> encoded input vectors are connected to the hidden layer via a <span class="math">\(V \times N\)</span> weight matrix <span class="math">\(\mathbf{W}\)</span> and the hidden layer is connected to the output layer via a <span class="math">\(N \times V\)</span> wieght matrix <span class="math">\(\mathbf{W'}\)</span>.</p>
<h1>Forward Propagation</h1>
<p>We must first understand how the output is computed from the input (i.e. forward propagation).  The following assumes that we know the input and output weight matrices (I will explain how these are actually learned in the next section).  The first step is to evaluate the output of the hidden layer <span class="math">\(\mathbf{h}\)</span>.  This is computed by</p>
<p>
<div class="math">$$\mathbf{h}=\frac{1}{C} \mathbf{W} \cdot (\sum^C_{i=1} \mathbf{x_i})$$</div>
</p>
<p>which is the average of the input vectors weighted by the matrix <span class="math">\(\mathbf{W}\)</span>.  It is worth noting that this hidden layer output computation is one of the only differences between the <em>continuous bag-of-words</em> model and the <em>skip-gram</em> model (in terms of them being mirror images of course).  Next we compute the inputs to each node in the output layer</p>
<p>
<div class="math">$$u_j= \mathbf{v'_{w_j}}^T \cdot \mathbf{h}$$</div>
</p>
<p>where <span class="math">\(\mathbf{v'_{w_j}}\)</span> is the <span class="math">\(j^{th}\)</span> column of the output matrix <span class="math">\(\mathbf{W'}\)</span>.  And finally we compute the output of the output layer.  The output <span class="math">\(y_j\)</span> is obtained by passing the input <span class="math">\(u_j\)</span> throught the soft-max function.</p>
<p>
<div class="math">$$y_j=p(w_{y_j} | w_1,...,w_C)=\frac{\exp(u_j)}{\sum^V_{j'=1} \exp(u_j')}$$</div>
</p>
<p>Now that we know how forward propagation works we can learn the weight matrices <span class="math">\(\mathbf{W}\)</span> and <span class="math">\(\mathbf{W'}\)</span>.  </p>
<h1>Learning the Weight Matrices with Backpropagation</h1>
<p>In the process of learning the wieght matrices <span class="math">\(\mathbf{W}\)</span> and <span class="math">\(\mathbf{W'}\)</span>, we begin with randomly initialized values.  We then sequentially feed training examples into our model and observe the error which is some function of the difference between the expected output and the actual output.  We then compute the gradient of this error with respect to the elements of both weight matrices and correct them in the direction of this gradient.  This general optimization procedure is known as stochastic gradient descent (or sgd) but the method by which the gradients are derived is known as backpropagation.  </p>
<p>The first step is to define the loss function.  The objective is to maximize the conditional probability of the output word given the input context, therefore our loss function will be</p>
<p>
<div class="math">$$\begin{align}
E &amp;= -\log p(w_O | w_I) \\
&amp;= -u_{j*} - \log \sum_{j'=1}^V \exp(u_{j'})  \\
&amp;=- \mathbf{v_{w_O}}^T \cdot \mathbf{h} - \log \sum_{j'=1}^V \exp(\mathbf{v_{w_{j'}}}^T \cdot \mathbf{h}) 
\end{align}$$</div>
</p>
<p>Where <span class="math">\(j^*\)</span> is the index of the the actual output word.  The next step is to derive the update equation for the hidden-output layer weights <span class="math">\(\mathbf{W'}\)</span>, then derive the weights for the input-hidden layer weights <span class="math">\(\mathbf{W}\)</span></p>
<h2>Updating the hidden-output layer weights</h2>
<p>The first step is to compute the derivative of the loss function <span class="math">\(E\)</span> with respect to the input to the <span class="math">\(j^{th}\)</span> node in the output layer <span class="math">\(u_j\)</span>.</p>
<p>
<div class="math">$$\frac{\partial{E}}{\partial{u_j}}=y_j - t_j$$</div>
</p>
<p>where <span class="math">\(t_j=1\)</span> if <span class="math">\(j=j^*\)</span> otherwise <span class="math">\(t_j=0\)</span>.  This is simply the prediction error of node <span class="math">\(j\)</span> in the output layer.  Next we take the derivative of <span class="math">\(E\)</span> with respect to the output weight <span class="math">\(w'_{ij}\)</span> using the chain rule.</p>
<p>
<div class="math">$$\begin{align}
\frac{\partial{E}}{\partial{w'_{ij}}} &amp;= \frac{\partial{E}}{\partial{u_j}} \cdot \frac{\partial{u_j}}{\partial{w'_{ij}}} \\
&amp;= (y_j - t_j) \cdot h_i
\end{align}$$</div>
</p>
<p>Now that we have the gradient with respect to an arbitrary output weight <span class="math">\(w'_{ij}\)</span>, we can define the stochastic gradient descent equation.</p>
<p>
<div class="math">$$w_{ij}^{'(new)}=w_{ij}^{'(old)} - \eta \cdot (y_j - t_j) \cdot h_i$$</div>
</p>
<p>or
<div class="math">$$\mathbf{v'_{w_j}}^{(new)}=\mathbf{v'_{w_j}}^{(old)} - \eta \cdot (y_j - t_j) \cdot \mathbf{h}$$</div>
</p>
<p>where <span class="math">\(\eta&gt;0\)</span> is the learning rate. </p>
<h2>Updating the input-hidden layer weights</h2>
<p>Now let's try to derive a similar update equation for the input weights <span class="math">\(w_{ij}\)</span>.  The first step is to compute the derivative of <span class="math">\(E\)</span> with respect to an arbitrary hidden node <span class="math">\(h_i\)</span> (again using the chain rule).</p>
<p>
<div class="math">$$
\begin{align}
\frac{\partial{E}}{\partial{h_i}} &amp;= \sum^V_{j=1} \frac{\partial{E}}{\partial{u_j}} \cdot \frac{\partial{u_j}}{\partial{h_i}} \\
&amp;= \sum^V_{j=1} (y_j - t_j) \cdot w'_{ij}
\end{align}
$$</div>
</p>
<p>where the sum is do to the fact that the hidden layer node <span class="math">\(h_i\)</span> is connected to each node of the output layer and therefore each prediction error must be incorporated.  The next step is to compute the derivative of <span class="math">\(E\)</span> with respect to an arbitrary input weight <span class="math">\(w_{ki}\)</span>.</p>
<p>
<div class="math">$$
\begin{align}
\frac{\partial{E}}{\partial{w_{ki}}} &amp;= \frac{\partial{E}}{\partial{h_i}} \cdot \frac{\partial{h_i}}{\partial{w_{ki}}}\\
 &amp;= \sum^V_{j=1} (y_j - t_j) \cdot w'_{ij} \cdot \frac{1}{C} \cdot x_k \\
 &amp; = \frac{1}{C}(\mathbf{x} \cdot EH)
\end{align}
$$</div>
</p>
<p>Where <span class="math">\(EH\)</span> is an N-dimensional vector of elements <span class="math">\(\sum^V_{j=1} (y_j - t_j) \cdot w'_{ij}\)</span> from <span class="math">\(i=1,...,N\)</span>.  However, since the inputs <span class="math">\(\mathbf{x}\)</span> are <em>one-hot</em> encoded, only one row of the <span class="math">\(N \times V\)</span> matrix <span class="math">\(\frac{1}{C}(\mathbf{x} \cdot EH)\)</span> will be nonzero.  Thus the final stochastic gradient descent equation for the input weights is</p>
<p>
<div class="math">$$\mathbf{v'_{w_{I,c}}}^{(new)}=\mathbf{v'_{w_{I,c}}}^{(old)} - \eta \cdot \frac{1}{C} \cdot EH$$</div>
</p>
<p>where <span class="math">\(w_{I,c}\)</span> is the <span class="math">\(c^{th}\)</span> word in the input context.</p>
<h2>References</h2>
<ul>
<li><a href="http://alexminnaar.com/word2vec-tutorial-part-i-the-skip-gram-model.html">Word2Vec Tutorial Part I: The Skip-Gram Model</a></li>
<li><a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>, Mikolov et al.</li>
<li><a href="http://arxiv.org/abs/1103.0398">Natural Language Processing (almost) from Scratch</a>, Collobert et al.</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/word2vec-tutorial-part-i-the-skip-gram-model.html">Word2Vec Tutorial Part I: The Skip-Gram Model</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2015-04-12T00:00:00+02:00">
          on&nbsp;Sun 12 April 2015
        </li>

	</ul>
<p>Category: <a href="/tag/nlp.html">   NLP</a><a href="/tag/supervised-learning.html">   Supervised Learning</a></p>
</div><!-- /.post-info --><p>In many natural language processing tasks, words are often represented by their <em>tf-idf</em> scores.  While these scores give us some idea of a word's relative importance in a document, they do not give us any insight into its semantic meaning.  <em>Word2Vec</em> is the name given to a class of neural network models that, given an unlabelled training corpus, produce a vector for each word in the corpus that encodes its semantic information.  These vectors are usefull for two main reasons.</p>
<ol>
<li>We can measure the semantic similarity between two words are by calculating the cosine similarity between their corresponding word vectors.  </li>
<li>We can use these word vectors as features for various supervised NLP tasks such as document classification, named entity recognition, and sentiment analysis.  The semantic information that is contained in these vectors make them powerful features for these tasks.</li>
</ol>
<p>You may ask <em>"how do we know that these vectors effectively capture the semantic meanings of the words?"</em>.  The answer is because the vectors adhere surprisingly well to our intuition.  For instance, words that we know to be synonyms tend to have similar vectors in terms of cosine similarity and antonyms tend to have dissimilar vectors.  Even more surprisingly, word vectors tend to obey the laws of analogy.  For example, consider the analogy <em>"Woman is to queen as man is to king"</em>.  It turns out that</p>
<p>
<div class="math">$$v_{queen}-v_{woman}+v_{man} \approx v_{king}$$</div>
</p>
<p>where <span class="math">\(v_{queen}\)</span>,<span class="math">\(v_{woman}\)</span>,<span class="math">\(v_{man}\)</span>, and <span class="math">\(v_{king}\)</span> are the word vectors for <span class="math">\(queen\)</span>, <span class="math">\(woman\)</span>, <span class="math">\(man\)</span>, and <span class="math">\(king\)</span> respectively.  These observations strongly suggest that word vectors encode valuable semantic information about the words that they represent. </p>
<p>In this series of blog posts I will describe the two main <em>Word2Vec</em> models - the <em>skip-gram model</em> and the <em>continuous bag-of-words</em> model.</p>
<p>Both of these models are simple neural networks with one hidden layer.  The word vectors are learned via backpropagation and stochastic gradient descent both of which I descibed in my previous <a href="http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html">Deep Learning Basics</a> blog post.</p>
<h1>The Skip-Gram Model</h1>
<p>Before we define the <em>skip-gram</em> model, it would be instructive to understand the format of the training data that it accepts.  The input of the <em>skip-gram</em> model is a single word <span class="math">\(w_I\)</span> and the output is the words in <span class="math">\(w_I\)</span>'s context <span class="math">\(\{w_{O,1},...,w_{O,C}\}\)</span> defined by a word window of size <span class="math">\(C\)</span>.  For example, consider the sentence <em>"I drove my car to the store"</em>.  A potential training instance could be the word "car" as an input and the words {"I","drove","my","to","the","store"} as outputs.  All of these words are <em>one-hot</em> encoded meaning they are vectors of length <span class="math">\(V\)</span> (the size of the vocabulary) with a value of <span class="math">\(1\)</span> at the index corresponding to the word and zeros in all other indexes.  As you can see, we are essentially <em>creating</em> training examples from plain text which means that we can have a virtually unlimited number of training examples at our disposal.</p>
<h2>Forward Propagation</h2>
<p>Now let's define the <em>skip-gram</em> nerual network model as follows.</p>
<p><img alt="skip-gram model" src="images/skip-gram.png" /> </p>
<p>In the above model <span class="math">\(\mathbf{x}\)</span> represents the <em>one-hot</em> encoded vector corresponding to the input word in the training instance and <span class="math">\(\{\mathbf{y_1},...\mathbf{y_C}\}\)</span> are the <em>one-hot</em> encoded vectors corresponding to the output words in the training instance.  The <span class="math">\(V \times N\)</span> matrix <span class="math">\(\mathbf{W}\)</span> is the weight matrix between the input layer and hidden layer whose <span class="math">\(i^{th}\)</span> row represents the weights corresponding to the <span class="math">\(i^{th}\)</span> word in the vocabulary. This weight matrix <span class="math">\(\mathbf{W}\)</span> is what we are interested in learning because it contains the vector encodings of all of the words in our vocabulary (as its rows).  Each output word vector also has an associated <span class="math">\(N \times V\)</span> output matrix <span class="math">\(\mathbf{W'}\)</span>. There is also a hidden layer consisting of <span class="math">\(N\)</span> nodes (the exact size of <span class="math">\(N\)</span> is a training parameter).</p>
<p>From my <a href="http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html">previous blog post</a>, we know that the input to a unit in the hidden layer <span class="math">\(h_i\)</span> is simply the weighted sum of its inputs.  Since the input vector <span class="math">\(\mathbf{x}\)</span> is <em>one-hot</em> encoded, the weights coming from the nonzero element will be the only ones contributing to the hidden layer.  Therefore, for the input <span class="math">\(\mathbf{x}\)</span> with <span class="math">\(x_k=1\)</span> and <span class="math">\(x_{k'}=0\)</span> for all <span class="math">\(k' \neq k\)</span> the outputs of the hidden layer will be equivalent to the <span class="math">\(k^{th}\)</span> row of <span class="math">\(\mathbf{W}\)</span>.  Or mathematically,</p>
<p>
<div class="math">$$\mathbf{h}=\mathbf{x}^T \mathbf{W}=\mathbf{W}_{(k, .)} := \mathbf{v}_{w_I}$$</div>
</p>
<p>Notice that there is no activation function used here.  This is presumably because the inputs are bounded by the <em>one-hot</em> encoding.  In the same way, the inputs to each of the <span class="math">\(C \times V\)</span> output nodes is computed by the weighted sum of its inputs.  Therefore, the input to the <span class="math">\(j^{th}\)</span> node of the <span class="math">\(c^{th}\)</span> output word is</p>
<p>
<div class="math">$$u_{c,j}=\mathbf{v'}_{w_j}^T \mathbf{h}$$</div>
</p>
<p>However we can also observe that the output layers for each output word share the same weights therefore <span class="math">\(u_{c,j}=u_j\)</span>.  We can finally compute the output of the <span class="math">\(j^{th}\)</span> node of the <span class="math">\(c^{th}\)</span> output word via the <em>softmax</em> function which produces a multinomial distribution </p>
<p>
<div class="math">$$p(w_{c,j}=w_{O,c} | w_I)=y_{c,j}=\frac{exp(u_{c,j})}{\sum_{j'=1}^V exp(u_{j'})}$$</div>
</p>
<p>In plain english, this value is the probability that the output of the <span class="math">\(j^{th}\)</span> node of the <span class="math">\(c^{th}\)</span> output word is equal to the actual value of the <span class="math">\(j^{th}\)</span> index of the <span class="math">\(c^{th}\)</span> output vector (which is <em>one-hot</em> encoded).</p>
<h2>Learning the Weights with Backpropagation and Stochastic Gradient Descent</h2>
<p>Now that we know how inputs are propograted forward through the network to produce outputs, we can derive the error gradients necessary for the backpropagation algorithm which we will use to learn both <span class="math">\(\mathbf{W}\)</span> and <span class="math">\(\mathbf{W'}\)</span>.  The first step in deriving the gradients is defining a loss function.  This loss function will be</p>
<p>
<div class="math">$$\begin{align}
E &amp;= -\log p(w_{O,1}, w_{O,2}, ..., w_{O,C} | w_I) \\
&amp;= -\log \prod^C_{c=1} \frac{exp(u_{c,j^*_c})}{\sum^V_{j'=1} exp(u_j')} \\
&amp;= -\sum^C_{c=1}u_{j^*_c} +C \cdot \log \sum^V_{j'=1} exp(u_{j'})
\end{align}$$</div>
</p>
<p>which is simply the probability of the output words (the words in the input word's context) given the input word.  Here, <span class="math">\(j^*_c\)</span> is the index of the <span class="math">\(c^{th}\)</span> output word.  If we take the derivative with respect to <span class="math">\(u_{c,j}\)</span> we get</p>
<p>
<div class="math">$$\frac{\partial{E}}{\partial{u_{c,j}}}=y_{c,j}-t_{c,j}$$</div>
</p>
<p>where <span class="math">\(t_{c,j}=1\)</span> if the <span class="math">\(j^{th}\)</span> node of the <span class="math">\(c^{th}\)</span> true output word is equal to <span class="math">\(1\)</span> (from its <em>one-hot</em> encoding), otherwise <span class="math">\(t_{c,j}=1\)</span>.  This is the prediction error for node <span class="math">\(c,j\)</span> (or the <span class="math">\(j^{th}\)</span> node of the <span class="math">\(c^{th}\)</span> output word).</p>
<p>Now that we have the error derivative with respect to inputs of the final layer, we can derive the derivative with respect to the output matrix <span class="math">\(\mathbf{W'}\)</span>.  Here we use the chain rule </p>
<p>
<div class="math">$$\begin{align}
\frac{\partial E}{\partial w'_{ij}} &amp;=\sum^C_{c=1} \frac{\partial E}{\partial u_{c,j}} \cdot \frac{\partial u_{c,j}}{\partial w'_{ij}} \\
&amp;=\sum^C_{c=1} (y_{c,j}-t_{c,j}) \cdot h_i
\end{align}$$</div>
</p>
<p>Therefore the gradient descent update equation for the output matrix <span class="math">\(\mathbf{W'}\)</span> is</p>
<p>
<div class="math">$$w'^{(new)}_{ij} =w'^{(old)}_{ij}- \eta \cdot \sum^C_{c=1} (y_{c,j}-t_{c,j}) \cdot h_i$$</div>
</p>
<p>Now we can derive the update equation for the input-hidden layer weights in <span class="math">\(\mathbf{W}\)</span>.  Let's start by computing the error derivative with respect to the hidden layer.</p>
<p>
<div class="math">$$\begin{align}
\frac{\partial{E}}{\partial{h_i}} &amp;=\sum^V_{j=1} \frac{\partial{E}}{\partial{u_j}} \cdot \frac{\partial{u_j}}{\partial{h_i}}  \\
&amp;=\sum^V_{j=1} \sum^C_{c=1} (y_{c,j}-t_{c,j})  \cdot w'_{ij}
\end{align}$$</div>
</p>
<p>Now we are able to compute the derivative with respect to <span class="math">\(\mathbf{W}\)</span></p>
<p>
<div class="math">$$\begin{align}
\frac{\partial{E}}{\partial{w_{ki}}} &amp;=\frac{\partial{E}}{\partial{h_i}} \cdot \frac{\partial{h_i}}{\partial{w_{ki}}} \\
&amp;= \sum^V_{j=1} \sum^C_{c=1} (y_{c,j}-t_{c,j})  \cdot w'_{ij} \cdot x_k
\end{align}$$</div>
</p>
<p>and finally we arrive at our gradient descent equation for our input weights</p>
<p>
<div class="math">$$w^{(new)}_{ij} =w^{(old)}_{ij}- \eta \cdot \sum^V_{j=1} \sum^C_{c=1} (y_{c,j}-t_{c,j})  \cdot w'_{ij} \cdot x_j$$</div>
</p>
<p>As you can see, each gradient descent update requires a sum over the entire vocabulary <span class="math">\(V\)</span> which is computationally expensive.  In practice, computation techniques such as hierarchical softmax and negative sampling are used to make this computation more efficient.</p>
<h2>References</h2>
<ul>
<li><a href="word2vec-tutorial-part-ii-the-continuous-bag-of-words-model.html">Word2Vec Tutorial Part II: The Continuous Bag-of-Words Model</a></li>
<li><a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>, Mikolov et al.</li>
<li><a href="http://arxiv.org/abs/1103.0398">Natural Language Processing (almost) from Scratch</a>, Collobert et al.</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html">Deep Learning Basics: Neural Networks, Backpropagation and Stochastic Gradient Descent</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2015-02-14T00:00:00+01:00">
          on&nbsp;Sat 14 February 2015
        </li>

	</ul>
<p>Category: <a href="/tag/supervised-learning.html">   Supervised Learning</a></p>
</div><!-- /.post-info --><p>In the last couple of years <em>Deep Learning</em> has received a great deal of press.  This press is not without warrant - <em>Deep Learning</em> has produced stat-of-the-art results in many computer vision and speech processing tasks.  However, I believe that the press has given people the impression that <em>Deep Learning</em> is some kind of imprenetrable, esoteric field that can only be understood by academics.  In this blog post I want to try to erase that impression and provide a practical overview of some of <em>Deep Learning's</em> basic concepts.</p>
<p>At its core, <em>Deep Learning</em> is a class of of neural network models.  That is, a model with an input layer, an output layer, and an arbitrary number of hidden layers. These layers are made up of neurons or neural units.  They are called neurons because they share some similarities with the behaviour of the neurons present in the human brain (though this comparison has drawn a lot of criticism from neuroscientists).  For our purposes, we can think of a neuron as a nonlinear function of the weighted sum of its inputs.  Since the neuron is really the most basic part of any <em>Deep Learning</em> model it is a good place to start.</p>
<h1>The Single Neuron Model</h1>
<p>A neuron is a function that maps an input vector <span class="math">\(\{x_1,...,x_K\}\)</span> to a scalar output <span class="math">\(y\)</span> via a weight vector <span class="math">\(\{w_1,...,w_K\}\)</span> and a nonlinear function <span class="math">\(f\)</span>.</p>
<p><img alt="general graphical model" src="images/neuron.png" title="=100x20" /> </p>
<p>The function <span class="math">\(f\)</span> takes a weighted sum of the inputs and returns <span class="math">\(y\)</span>.</p>
<p>
<div class="math">$$y=f(\sum_{i=0}^Kw_ix_i)=f(\mathbf{w^Tx})$$</div>
</p>
<p>Often an additional element is added to the input vector that is always equal to <span class="math">\(1\)</span> with a corresponding additional weight element which acts as a bias.  The function <span class="math">\(f\)</span> is called the link function which provides the nonlinearity between the input and output.  A common choice for this link function is the <strong>logistic function</strong> which is defined as</p>
<p>
<div class="math">$$f(u)=\frac{1}{1+e^{u}}$$</div>
</p>
<p>With the appropriate substitutions the final formula for the single neuron model becomes</p>
<p>
<div class="math">$$y=\frac{1}{1+e^{\mathbf{w^Tx}}}$$</div>
</p>
<p>If you plot the logistic function,</p>
<p><img alt="general graphical model" src="images/logistic.png" /> </p>
<p>you can see that it is smooth and differentiable and bound between <span class="math">\(0\)</span> and <span class="math">\(1\)</span>.  We shall see that these are two important properties.  The derivative of the logistic function is simply</p>
<p>
<div class="math">$$\frac{d f(u)}{d u}=f(u)(1-f(u))=f(u)f(-u)$$</div>
</p>
<p>This derivative will be used when we learn the weight vector <span class="math">\(\bf{w}\)</span> via <strong>stochastic gradient descent</strong>.</p>
<p>Like any optimization problem, our goal is to minimize an objective function.  Traditionally, the objective function measures the difference between the actual output <span class="math">\(t\)</span> and the predicted output <span class="math">\(f(\mathbf{w^Tx})\)</span>. In this case we will be using the squared loss function</p>
<p>
<div class="math">$$E=\frac{1}{2}(t - y)^2=\frac{1}{2}(t-f(\mathbf{w^Tx}))^2$$</div>
</p>
<p>We want to find the weights <span class="math">\(\mathbf{w}\)</span> such that the above objective is minimized.  We do this with stochastic gradient descent (SGD).  In SGD we iteratively update our weight parameters in the direction of the gradient of the loss function until we have reached a minimum.  Unlike traditional gradient descent, we do not use the entire dataset to compute the gradient at each iteration.  Instead, at each iteration we randomly select a single data point from our dataset and move in the direction of the gradient with respect to that data point.  Obviously this is only an approximation of the true gradient but it can be proven that we will eventually reach the minimum by following this <em>noisey</em> gradient.  There are several advantages to using stochastic gradient descent over traditional gradient descent.</p>
<ol>
<li>Gradient descent requires loading the entire dataset into main memory.  If your dataset is large this can be problematic.  Stochastic gradient descent only requires one data point at a time (or sometimes a minibatch of data points) which is much less memory intensive.</li>
<li>Most datasets have redundancy in them.  Traditional gradient descent requires one full pass over the data until an update is made.  Due to redundancy, a meaningful update can often be made without iterating over the entire dataset as with stochastic gradient descent.</li>
<li>As a consequence of the previous point, stochastic gradient descent can often converge faster than traditional gradient descent.  It is also guaranteed to find the global minimum if the loss function is convex.</li>
</ol>
<p>Our objective function <span class="math">\(E\)</span> is already defined in terms of a single data point so let's procede to compute its gradient with respect to an aribtrary element of our weight vector <span class="math">\(w_i\)</span>.</p>
<p>
<div class="math">$$\begin{align}
\frac{\partial E}{\partial w_i} &amp;= \frac{\partial E}{\partial y} \cdot \frac{\partial y}{\partial u} \cdot\frac{\partial u}{\partial w_i} \\
&amp;= (y-t) \cdot y(1-y) \cdot x_i
\end{align}$$</div>
</p>
<p>Now we are able to obtain the stochastic gradient descent update equation (in vector notation)</p>
<p>
<div class="math">$$\mathbf{w}^{new}=\mathbf{w}^{old}- \eta \cdot (y-t) \cdot y(1-y) \cdot \mathbf{x}$$</div>
</p>
<p>Where <span class="math">\(\eta&gt;0\)</span> is the step size.  As stated previously, <span class="math">\((\mathbf{x},y)\)</span> data points are sequentially fed into this update equation until the weights <span class="math">\(\mathbf{w}\)</span> converge to their optimal value.  This is how we use stochastic gradient descent to learn the weights for the single neuron model.</p>
<p>What we just did is also known as <strong>logistic regression</strong> and if we had replaced our logistic function with a unit step function we would have made what is known as a <strong>perceptron</strong>!  Now let's extend this relatively simple model to something a bit more complex...</p>
<h1>The Neural Network</h1>
<p>A neural network consists of an input layer, output layer, and hidden layer. Our input layer consists of the input vector <span class="math">\(\mathbf{x}=\{x_1,...,x_K\}\)</span>.  The hidden layer  consists of a vector of <span class="math">\(N\)</span> neurons <span class="math">\(\mathbf{h}=\{h_1,...,h_N\}\)</span>.  Finally there is an output layer with one neuron for every element of the output vector <span class="math">\(\mathbf{y}=\{y_1,...,y_M\}\)</span>.  Every element in the input layer is connected to every neuron in the hidden layer with <span class="math">\(w_{ki}\)</span> indicating the weight associated with the connection between the <span class="math">\(k^{th}\)</span> input element and the <span class="math">\(i^{th}\)</span> hidden neuron.  The same connection structure is present between the hidden and output layers with  <span class="math">\(w'_{ij}\)</span> indicating the weight associated with the connection between the <span class="math">\(i^{th}\)</span> hidden neuron and the <span class="math">\(j^{th}\)</span> output neuron.  This network structure is better illustrated in the below diagram.</p>
<p><img alt="general graphical model" src="images/neural_network.png" title="=250x" /> </p>
<p>It is helpful to think of the weight <span class="math">\(w_{ki}\)</span> as the the <span class="math">\((k,i)^{th}\)</span> entry in a <span class="math">\(K \times N\)</span> weight matrix <span class="math">\(\mathbf{W}\)</span> and similarly weight <span class="math">\(w'_{ij}\)</span> as the <span class="math">\((i,j)^{th}\)</span> entry in a <span class="math">\(N \times M\)</span> weight matrix <span class="math">\(\mathbf{W'}\)</span>.  The output of each neuron in the hidden and output layer is computed in the exact same way as before.  It is simply the logistic function applied to the weighted sum of the neuron's inputs.  For example, the output of an arbitrary neuron in the hidden layer <span class="math">\(h_i\)</span> is</p>
<p>
<div class="math">$$h_i=f(u_i)=f(\sum^K_{k=1}w_{ki}x_k)$$</div>
</p>
<p>and similarly for the output of an arbitrary output neuron <span class="math">\(y_j\)</span> is</p>
<p>
<div class="math">$$y_j=f(u'_j)=f(\sum^N_{i=1}w'_{ij}h_i)$$</div>
</p>
<p>The objective function is also the same as before except now it is summed over all elements in the output layer.</p>
<p>
<div class="math">$$E=\frac{1}{2}\sum^M_{j=1}(y_j-t_j)^2$$</div>
</p>
<p>Unlike before, we need to construct update equations for <em>both</em> sets of weights - the input-to-hidden layer weights <span class="math">\(w_{ki}\)</span> and the hidden-to-output weights <span class="math">\(w'_{ij}\)</span>.  In order to do this we need to compute the gradient of our objective function <span class="math">\(E\)</span> with respect to <span class="math">\(w_{ki}\)</span> as well as the gradient with respect to <span class="math">\(w'_{ij}\)</span>.  We must start with the gradient with respect to <span class="math">\(w'_{ij}\)</span> (the hidden-to-output weights) and we shall see why later.  In order to compute <span class="math">\(\frac{\partial E}{\partial{w'_{ij}}}\)</span> we must recall our high-school calculus, specifically the chain rule.  From the chain rule, we must first take the derivative of <span class="math">\(E\)</span> with respect to <span class="math">\(y'_j\)</span>.  Then we must take the derivative of <span class="math">\(y_j\)</span> (i.e. the logistic function) with respect to <span class="math">\(w'_{ij}\)</span> which needs yet another application of the chain rule.  We first take the derivative of the logistic function with respect to its input <span class="math">\(u'_j\)</span>, then finally we can take the derivative of this input with respect to <span class="math">\(w'_{ij}\)</span> and we arrive at our desired value.  This process is clearly defined below.</p>
<p>From the chain rule,</p>
<p>
<div class="math">$$\frac{\partial E}{\partial w'_{ij}}=\frac{\partial E}{\partial y_j} \cdot \frac{\partial y_j}{\partial u'_j} \cdot \frac{\partial u'_j}{\partial w'_{ij}}$$</div>
</p>
<p>The derivative of <span class="math">\(E\)</span> with respect to <span class="math">\(y_j\)</span> is simply,</p>
<p>
<div class="math">$$\frac{\partial E}{\partial y_j}=y_j-t_j$$</div>
</p>
<p>From the last section we saw that the derivative of the logistic function <span class="math">\(f\)</span> with respect to its input <span class="math">\(u\)</span> is <span class="math">\(f(u)(1-f(u))\)</span>.  If we apply this we get,</p>
<p>
<div class="math">$$\frac{\partial y_j}{\partial u'_j}=y_j(1-y_j)$$</div>
</p>
<p>where <span class="math">\(y_j=f(u'_j)\)</span>.  Next we compute the derivative of <span class="math">\(u'_j=\sum^N_{i=1}w'_{ij}h_i\)</span> with respect to a particular <span class="math">\(w'_{ij}\)</span> which is simply <span class="math">\(h_i\)</span>.  So, after making the appropriate subsitutions, we get</p>
<p>
<div class="math">$$\frac{\partial E}{\partial w'_{ij}}=(y_j-t_j) \cdot y_j(1-y_j) \cdot h_i$$</div>
</p>
<p>With this gradient we can construct the update equation for <span class="math">\(w'_{ij}\)</span></p>
<p>
<div class="math">$$w'^{new}_{ij}=w'^{old}_{ij} - \eta \cdot (y_j-t_j) \cdot y_j(1-y_j) \cdot h_i$$</div>
</p>
<p>Now let's turn our attention to the gradient of the objective function with respect to the input-to-hidden weights <span class="math">\(w_{ki}\)</span>.  As we shall see, this gradient has already been partially computed when we computed the previous gradient.</p>
<p>Using the chain rule, the full gradient is</p>
<p>
<div class="math">$$\frac{\partial E}{\partial w_{ki}}=\sum^M_{j=1}(\frac{\partial E}{\partial y_j}\cdot \frac{\partial y_j}{\partial u'_j} \cdot \frac{\partial u'_j}{\partial h_i} )\cdot \frac{\partial h_i}{\partial u_i} \cdot \frac{\partial u_i}{\partial w_{ki}}$$</div>
</p>
<p>The sum is due to the fact that the hidden unit that <span class="math">\(w_{ki}\)</span> connects to is itself connected to every output unit, thus each of these gradients need to be taken into account as well.  We have already computed both <span class="math">\(\frac{\partial E}{\partial y_j}\)</span> and <span class="math">\(\frac{\partial y_j}{\partial u'_j}\)</span> which means that</p>
<p>
<div class="math">$$\frac{\partial E}{\partial y_j}\cdot \frac{\partial y_j}{\partial u'_j} = (y_j-t_j) \cdot y_j(1-y_j)$$</div>
</p>
<p>Now we need to compute the remaining derivatives <span class="math">\(\frac{\partial u'_j}{\partial h_i}\)</span>, <span class="math">\(\frac{\partial h_i}{\partial u_i}\)</span>, and <span class="math">\(\frac{\partial u_i}{\partial w_{ki}}\)</span>.  So let's do just that.</p>
<p>
<div class="math">$$\frac{\partial u'_j}{\partial h_i}=\frac{\partial \sum^N_{i=1}w'_{ij}h_i}{\partial h_i}=w'_{ij}$$</div>
</p>
<p>and, again using the derivative of the logistic function</p>
<p>
<div class="math">$$\frac{\partial h_i}{\partial u_i}=h_i(1-h_i)$$</div>
</p>
<p>and finally</p>
<p>
<div class="math">$$\frac{\partial u_i}{\partial w_{ki}}=\frac{\partial \sum^K_{k=1}w_{ki}x_k}{\partial w_{ki}}=x_k$$</div>
</p>
<p>After making the appropriate substitutions we arrive at the gradient</p>
<p>
<div class="math">$$\frac{\partial E}{\partial w_{ki}}=\sum^M_{j=1}[(y_j-t_j) \cdot y_j(1-y_j) \cdot w'_{ij}] \cdot h_i(1-h_i) \cdot x_k$$</div>
</p>
<p>And the update equation becomes</p>
<p>
<div class="math">$$w^{new}_{ki}=w^{old}_{ki} - \eta \cdot \sum^M_{j=1}[(y_j-t_j) \cdot y_j(1-y_j) \cdot w'_{ij}] \cdot h_i(1-h_i) \cdot x_k$$</div>
</p>
<p>This process is known as <strong>backpropagation</strong> because we begin with the final output error <span class="math">\(y_j-t_j\)</span> for the output neuron <span class="math">\(j\)</span> and this error gets propagated backwards throughout the network in order to update the weights.</p>
<h1>Wrapping Everything Up</h1>
<p>In this blog post we started with the simple single neuron model and we learned the model weights by computing the gradient of the objective function and using it in the stochastic gradient descent update equation.  Then we moved on to the slightly more complicated neural network model.  In this case we computed the required gradients using a procedure known as backpropagation and we again used these gradients in the SGD update equations.  True <em>Deep Learning</em> models either contain many more hidden layers or neurons in different configurations but they still adhere to the basic principles described here.  Hopefully this post has made <em>Deep Learning</em> seem like a more understandable and less daunting field of machine learning.</p>
<h1>References</h1>
<ul>
<li><a href="https://www.coursera.org/course/neuralnets">Neural Networks for Machine Learning</a> Coursera course from Geoffrey Hinton.</li>
<li><a href="http://deeplearning.stanford.edu/tutorial/">Deep Learning Tutorial</a> from Stanford.</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/time-series-classification-and-clustering-with-python.html">Time Series Classification and Clustering with Python</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2014-04-16T00:00:00+02:00">
          on&nbsp;Wed 16 April 2014
        </li>

	</ul>
<p>Category: <a href="/tag/supervised-learning.html">   Supervised Learning</a></p>
</div><!-- /.post-info --><p>I recently ran into a problem at work where I had to predict whether an account would churn  in the near future given the account's time series usage in a certain time interval.  So this is a binary-valued classification problem (i.e. churn or not churn) with a time series as a predictor.  This was not a very straight-forward problem to tackle because it seemed like there two possible strategies to employ.</p>
<ol>
<li>Extract features from the time series like its mean, maximum, minimum, and other differential features.  Then use well-known classification algorithms (Naive Bayes, SVMs, etc.) with these features to make a prediction.</li>
<li>Use a k-NN approach.  For a given time series example that you want to predict, find the most similar time series in the training set and use its corresponding output as the prediction.</li>
</ol>
<p>I tried both of these strategies and the latter produced the best results.  However this approach is not as simple as it may seem.  This is because finding a good similarity measure between time series is a very non-trivial task.</p>
<h2>Finding a Similarity Measure</h2>
<p>A naive choice for a similarity measure would be Euclidean distance.  The following example will show why this choice is not optimal.  Consider the following of 3 time series.</p>
<p><img alt="alt text" src="images/3_ts.png" title="time series examples" /> </p>
<p>In the above example, it is clear that <span class="math">\(ts1\)</span> and <span class="math">\(ts2\)</span> are most similar (they are both sin functions under different transformations). <span class="math">\(ts3\)</span> is clearly the most different. Let's compute the Euclidean distance <span class="math">\(d(ts1,ts2)\)</span> and <span class="math">\(d(ts1,ts3)\)</span> to see if the Euclidean distance measure agrees with what our intuition tells us. Let's first create a function that computes the Euclidean distance between two time series using</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">euclid_dist</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">((</span><span class="n">t1</span><span class="o">-</span><span class="n">t2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</pre></div>


<p>It turns out that <span class="math">\(d(ts1,ts2)=26.9\)</span> and <span class="math">\(d(ts1,ts3)=23.2\)</span>. This is not good because according to the Euclidean distance measure, <span class="math">\(ts1\)</span> is more similar to <span class="math">\(ts3\)</span> than to <span class="math">\(ts2\)</span> which contradicts our intuition. This is the problem with using the Euclidean distance measure. It often produced pessimistic similarity measures when it encounters distortion in the time axis. The way to deal with this is to use dynamic time warping.</p>
<h3>Dynamic Time Warping</h3>
<p>Dynamic time warping finds the optimal non-linear alignment between two time series. The Euclidean distances between alignments are then much less susceptible to pessimistic similarity measurements due to distortion in the time axis. There is a price to pay for this, however, because dynamic time warping is quadratic in the length of the time series used.</p>
<p>Dynamic time warping works in the following way. Consider two time series <span class="math">\(Q\)</span> and <span class="math">\(C\)</span> of the same length <span class="math">\(n\)</span> where <span class="math">\(Q=q_1,q_2,...,q_n\)</span> and <span class="math">\(C=c_1,c_2,...,c_n\)</span> The first thing we do is construct an <span class="math">\(n\times n\)</span> matrix whose <span class="math">\(i,j^{th}\)</span> element is the Euclidean distance between <span class="math">\(q_i\)</span> and <span class="math">\(c_j\)</span>. We want to find a path through this matrix that minimizes the cumulative distance. This path then determines the optimal alignment between the two time series. It should be noted that it is possible for one point in a time series to be mapped to multiple points in the other time series.</p>
<p>Let's call the path <span class="math">\(W\)</span> where <span class="math">\(W=w_1,w_2,...,w_K\)</span> where each element of <span class="math">\(W\)</span> represents the distance between a point <span class="math">\(i\)</span> in <span class="math">\(Q\)</span> and a point <span class="math">\(j\)</span> in <span class="math">\(C\)</span> i.e. <span class="math">\(w_k=(q_i-c_j)^2\)</span></p>
<p>So we want to find the path with the minimum Euclidean distance <span class="math">\(W^*=argmin_W(\sqrt{\sum_{k=1}^Kw_k})\)</span> The optimal path is found via dynamic programming, specifically the following recursive function. <span class="math">\(\gamma(i,j)=d(q_i,c_j)+min ( \gamma(i-1,j-1),\gamma(i-1,j),\gamma(i,j-1))\)</span>. This can be implemented via the following python function.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">DTWDistance</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">):</span>
    <span class="n">DTW</span><span class="o">=</span><span class="p">{}</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)):</span>
        <span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">&#39;inf&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)):</span>
        <span class="n">DTW</span><span class="p">[(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">&#39;inf&#39;</span><span class="p">)</span>
    <span class="n">DTW</span><span class="p">[(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)):</span>
            <span class="n">dist</span><span class="o">=</span> <span class="p">(</span><span class="n">s1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">s2</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="n">dist</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">)],</span><span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>

    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">DTW</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>


<p>The dynamic time warping Euclidean distances between the time series are <span class="math">\(DTWDistance(ts1,ts2)=17.9\)</span> and <span class="math">\(DTWDistance(ts1,ts3)=21.5\)</span>. As you can see, our results have changed from when we only used the Euclidean distance measure. Now, in agreement with our intuition, <span class="math">\(ts2\)</span> is shown to be more similar to <span class="math">\(ts1\)</span> than <span class="math">\(ts3\)</span> is.</p>
<h3>Speeding Up Dynamic Time Warping</h3>
<p>Dynamic time warping has a complexity of <span class="math">\(O(nm)\)</span> where <span class="math">\(n\)</span> is the length of the first time series and <span class="math">\(m\)</span> is the length of the second time series. If you are performing dynamic time warping multiple times on long time series data, this can be prohibitively expensive. However, there are a couple of ways to speed things up. The first is to enforce a locality constraint. This works under the assumption that it is unlikely for <span class="math">\(q_i\)</span> and <span class="math">\(c_j\)</span> to be matched if <span class="math">\(i\)</span> and <span class="math">\(j\)</span> are too far apart. The threshold is determined by a window size <span class="math">\(w\)</span>. This way, only mappings within this window are considered which speeds up the inner loop. The following is the modified code which includes the window size <span class="math">\(w\)</span>.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">DTWDistance</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
    <span class="n">DTW</span><span class="o">=</span><span class="p">{}</span>

    <span class="n">w</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)):</span>
            <span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">&#39;inf&#39;</span><span class="p">)</span>
    <span class="n">DTW</span><span class="p">[(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="o">-</span><span class="n">w</span><span class="p">),</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">),</span> <span class="n">i</span><span class="o">+</span><span class="n">w</span><span class="p">)):</span>
            <span class="n">dist</span><span class="o">=</span> <span class="p">(</span><span class="n">s1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">s2</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span> <span class="o">=</span> <span class="n">dist</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">)],</span><span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">DTW</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>

    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">DTW</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>


<p>Another way to speed things up is to use the LB Keogh lower bound of dynamic time warping. It is defined as </p>
<p><span class="math">\(LBKeogh(Q,C)=\sum_{i=1}^n (c_i-U_i)^2I(c_i &gt; U_i)+(c_i-L_i)^2I(c_i &lt; L_i)\)</span> </p>
<p>where <span class="math">\(U_i\)</span> and <span class="math">\(L_i\)</span> are upper and lower bounds for time series <span class="math">\(Q\)</span> which are defined as <span class="math">\(U_i=max(q_{i-r}:q_{i+r})\)</span> and <span class="math">\(L_i=min(q_{i-r}:q_{i+r})\)</span> for a reach <span class="math">\(r\)</span> and <span class="math">\(I(\cdot)\)</span> is the indicator function. It can be implemented with the following function.</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">LB_Keogh</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span><span class="n">s2</span><span class="p">,</span><span class="n">r</span><span class="p">):</span>
    <span class="n">LB_sum</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">s1</span><span class="p">):</span>

        <span class="n">lower_bound</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">s2</span><span class="p">[(</span><span class="n">ind</span><span class="o">-</span><span class="n">r</span> <span class="k">if</span> <span class="n">ind</span><span class="o">-</span><span class="n">r</span><span class="o">&gt;=</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">):(</span><span class="n">ind</span><span class="o">+</span><span class="n">r</span><span class="p">)])</span>
        <span class="n">upper_bound</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">s2</span><span class="p">[(</span><span class="n">ind</span><span class="o">-</span><span class="n">r</span> <span class="k">if</span> <span class="n">ind</span><span class="o">-</span><span class="n">r</span><span class="o">&gt;=</span><span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span><span class="p">):(</span><span class="n">ind</span><span class="o">+</span><span class="n">r</span><span class="p">)])</span>

        <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="n">upper_bound</span><span class="p">:</span>
            <span class="n">LB_sum</span><span class="o">=</span><span class="n">LB_sum</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="n">upper_bound</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">elif</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">lower_bound</span><span class="p">:</span>
            <span class="n">LB_sum</span><span class="o">=</span><span class="n">LB_sum</span><span class="o">+</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="n">lower_bound</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">LB_sum</span><span class="p">)</span>
</pre></div>


<p>The LB Keogh lower bound method is linear whereas dynamic time warping is quadratic in complexity which make it very advantageous for searching over large sets of time series.</p>
<h2>Classification and Clustering</h2>
<p>Now that we have a reliable method to determine the similarity between two time series, we can use the k-NN algorithm for classification. Empirically, the best results have come when <span class="math">\(k=1\)</span>. The following is the 1-NN algorithm that uses dynamic time warping Euclidean distance. In this algorithm, <span class="math">\(train\)</span> is the training set of time series examples where the class that the time series belongs to is appended to the end of the time series. <span class="math">\(test\)</span> is the test set whose corresponding classes you are trying to predict. In this algorithm, for every time series in the test set, a search must be performed through all points in the training set so that the most similar point is found. Given that dynamic time warping is quadratic, this can be very computationally expensive. We can speed up classification using the LB Keogh lower bound. Computing LB Keogh is much less expensive than performing dynamic time warping. And since <span class="math">\(LB Keogh(Q,C) \leq DTW(Q,C)\)</span> , we can eliminate time series that cannot possibly be more similar that the current most similar time series. In this way we are eliminating many unnecessary dynamic time warping computations.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="k">def</span> <span class="nf">knn</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="n">w</span><span class="p">):</span>
    <span class="n">preds</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test</span><span class="p">):</span>
        <span class="n">min_dist</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s">&#39;inf&#39;</span><span class="p">)</span>
        <span class="n">closest_seq</span><span class="o">=</span><span class="p">[]</span>
        <span class="c">#print ind</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">train</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">LB_Keogh</span><span class="p">(</span><span class="n">i</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">j</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="mi">5</span><span class="p">)</span><span class="o">&lt;</span><span class="n">min_dist</span><span class="p">:</span>
                <span class="n">dist</span><span class="o">=</span><span class="n">DTWDistance</span><span class="p">(</span><span class="n">i</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">j</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">w</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">dist</span><span class="o">&lt;</span><span class="n">min_dist</span><span class="p">:</span>
                    <span class="n">min_dist</span><span class="o">=</span><span class="n">dist</span>
                    <span class="n">closest_seq</span><span class="o">=</span><span class="n">j</span>
        <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">closest_seq</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">preds</span><span class="p">)</span>
</pre></div>


<p>Now let's test it on some data. We will use a window size of 4. Although the code is sped up with the use of the LB Keogh bound and the dynamic time warping locality constraint, it may still take a few minutes to run.</p>
<div class="highlight"><pre><span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">&#39;datasets/train.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">&#39;datasets/test.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
<span class="k">print</span> <span class="n">knn</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
</pre></div>


<p>The result is</p>
<p><img alt="alt text" src="images/perfromance.jpg" title="performance" /> </p>
<p>The same idea can also be applied to k-means clustering. In this algorithm, the number of clusters is set apriori and similar time series are clustered together.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">k_means_clust</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">num_clust</span><span class="p">,</span><span class="n">num_iter</span><span class="p">,</span><span class="n">w</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">centroids</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">num_clust</span><span class="p">)</span>
    <span class="n">counter</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iter</span><span class="p">):</span>
        <span class="n">counter</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">print</span> <span class="n">counter</span>
        <span class="n">assignments</span><span class="o">=</span><span class="p">{}</span>
        <span class="c">#assign data points to clusters</span>
        <span class="k">for</span> <span class="n">ind</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">min_dist</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s">&#39;inf&#39;</span><span class="p">)</span>
            <span class="n">closest_clust</span><span class="o">=</span><span class="bp">None</span>
            <span class="k">for</span> <span class="n">c_ind</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroids</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">LB_Keogh</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span><span class="o">&lt;</span><span class="n">min_dist</span><span class="p">:</span>
                    <span class="n">cur_dist</span><span class="o">=</span><span class="n">DTWDistance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">w</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">cur_dist</span><span class="o">&lt;</span><span class="n">min_dist</span><span class="p">:</span>
                        <span class="n">min_dist</span><span class="o">=</span><span class="n">cur_dist</span>
                        <span class="n">closest_clust</span><span class="o">=</span><span class="n">c_ind</span>
            <span class="k">if</span> <span class="n">closest_clust</span> <span class="ow">in</span> <span class="n">assignments</span><span class="p">:</span>
                <span class="n">assignments</span><span class="p">[</span><span class="n">closest_clust</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">assignments</span><span class="p">[</span><span class="n">closest_clust</span><span class="p">]</span><span class="o">=</span><span class="p">[]</span>

        <span class="c">#recalculate centroids of clusters</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">assignments</span><span class="p">:</span>
            <span class="n">clust_sum</span><span class="o">=</span><span class="mi">0</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">assignments</span><span class="p">[</span><span class="n">key</span><span class="p">]:</span>
                <span class="n">clust_sum</span><span class="o">=</span><span class="n">clust_sum</span><span class="o">+</span><span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">centroids</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="n">m</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">assignments</span><span class="p">[</span><span class="n">key</span><span class="p">])</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">clust_sum</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">centroids</span>
</pre></div>


<p>Let's test it on the entire data set (i.e. the training set and the test set stacked together).</p>
<div class="highlight"><pre><span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">&#39;datasets/train.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">&#39;datasets/test.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">train</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">test</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">centroids</span><span class="o">=</span><span class="n">k_means_clust</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">centroids</span><span class="p">:</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="alt text" src="images/cluster.png" title="cluster" /> </p>
<h3>Code</h3>
<p>The code used in this blog post can be found in <a href="https://github.com/alexminnaar/time-series-classification-and-clustering">my gitHub repo</a>.</p>
<h3>References</h3>
<p>The vast majority of research in this area is done by Dr. Eamonn Keogh's group at UC Riverside.  All of the relevant papers are referenced in <a href="http://www.cs.ucr.edu/~eamonn/time_series_data/">the group's webpage</a>.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                    </article>
                </div>
            </aside><!-- /#featured -->
            
        
        

    
            <aside id="featured">
                <div class="body">
                    <article>
                        <h1 class="entry-title"><a href="/my-experience-with-churn-analysis.html">My Experience with Churn Analysis</a></h1>
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="/author/alex-minnaar.html">Alex Minnaar</a>
        </li>
        <li class="published" title="2014-03-30T00:00:00+01:00">
          on&nbsp;Sun 30 March 2014
        </li>

	</ul>
<p>Category: <a href="/tag/supervised-learning.html">   Supervised Learning</a></p>
</div><!-- /.post-info --><p>A large chunk of my time at my last job was devoted to churn analysis and I wanted to use this blog entry to explain how I approached the various problems that it presented.  This is not meant to be a very technical post and the reasoning behind this is two-fold</p>
<ol>
<li>Obviously I do not have permission to use any company data and there is not really any good publicly-available churn datasets on the web.  Presenting technical code without data to run it on would not really make sense.</li>
<li>I have learned that churn analysis is very domain-specific and I want to make sure that what I say generalizes to many use-cases.</li>
</ol>
<p>Before I explain what I did, I should first define what churn is and the specific goals that I had in mind.</p>
<h2>What is Churn?</h2>
<p>Churn is a term that generally describes the process where customers stop using the products and/or services provided by a business.  However, it is of most interest in subscription-based services like phone plans, video games, etc.  In these services it is easy to know when a customer has churned i.e. when they cancel their subscription.  Needless to say, churn is bad for business.  Every company has a customer CPA (Cost Per Acquisition) so in order to replace a churned customer with a new customer, this cost must be paid.   Clearly it is cheaper for companies to keep customers than to replace them.  Churn analysis is used to attempt to answer the following questions</p>
<ol>
<li>Why are customers churning?</li>
<li>Can we predict customers who will churn in the near future (and then maybe convince them to stay with us)?</li>
<li>How long can we expect a given customer to stay with us?</li>
</ol>
<p>These are very important questions and if reliable answers can be obtained, they would be of great value.  We will also see that these main questions are closely linked to some other slightly different yet equally important questions such as</p>
<ol>
<li>What is the lifetime value of a given customer?</li>
<li>Who are our most valuable customers and who are out least valuable customers? What accounts for these differences?</li>
</ol>
<h2>Question:  Can we predict which customers will churn in the near future?</h2>
<p>Predicting which of your current customers will churn is a binary classification problem.  As it stands, this is an ill-defined problem.  This is because of the simple fact that in subscription-based services ALL CUSTOMERS WILL CANCEL EVENTUALLY!  You could have a classifier that predicts that all currently active accounts will cancel and it would be 100% correct!  But obviously this would be useless to a company.  What companies really want to know is which of the currently active accounts will cancel "soon".  This way companies can take action in an effort to prevent cancellation from occurring.  The specific preventative action that should be taken is beyond the scope of this blog post but the prediction problem itself will be explored.</p>
<h3>Dealing with the Time Component</h3>
<p>The first thing that you need to do is define a time period.  There is a trade-off here.  You want to know who is going to cancel as soon as possible so that you have the maximum amount of time to take preventative action. However if you predict too early, your predictions will be of lower quality.  This is because (in most cases) churn indicators become clearer the closer the customer is to his/her actual cancel date.  On the other hand, if you predict too late, your predictions will be more reliable but it will give you less time to take preventative action.  You need to decide on a good balance which most likely depends on your domain.  I can say that in the telecom domain a 2 week window is generally enough time to perform preventative action.</p>
<p>Once you have dealt with the time component, the classification problem becomes more well-defined however there is still a bit more work that needs to be done.</p>
<h3>Defining Positive and Negative Examples</h3>
<p>In any classification problem you need to build a training set of positive and negative examples.  It is clear that negative examples will come from customers that have churned in the past.  However it is a bit unclear what the positive examples should be.  You might initially think that we can use the currently active accounts as positive examples.  This is problematic sinse ultimately these are the accounts we will test on so we can't really use them for training as they are.</p>
<p>What you need to do is identify your long-time customers (they will most likely be currently active, but they could also have cancelled after using your service for a long time).  However, as previously stated, you cannot use them as they are because you are going to test on them.  You need to use the truncated versions of these examples as positive examples.  For example, if you have a long-time customer that has been active for two years, use this customer's behaviour from their first 365 days as a positive example.  In this way, you obtain positive examples of customers that you know will not cancel for a long time.  Also, testing will generally be done on an active customer's recent behaviour, so you are mitigating the risk of overfitting by training on that customer's past behaviour.</p>
<p>Now that you know what your positive and negative examples are you must extract relevant feature from them.</p>
<h3>Feature Extraction</h3>
<p>The feature extraction process is the most important part of this problem and, unfortunately, also the most unsystematic.  If you have dealt with supervised learning problems before you know that feature extraction is as much an art as it is a science.  Feature extraction is very domain-specific.  In some cases the relevant features that indicate churn likelihood are obvious, in others it is less clear.  It would be wise to consult someone with good domain expertise before you decide on the features you will use.  I will list some of the features that I found to be good indicators of churn in the telecom domain.</p>
<h4>Static Features</h4>
<p>Static features are features that are not time-dependent.</p>
<ul>
<li>Age at activation date</li>
<li>Lead source</li>
<li>Type of phone</li>
<li>Number of phones attached to account</li>
<li>Location</li>
<li>Credit card type</li>
</ul>
<h4>Usage-based Features</h4>
<p>Usage-based features deal with the customer's time-dependent usage patterns.</p>
<ul>
<li>Date of last usage</li>
<li>Max and min daily usage amount</li>
<li>Average usage amount over last 30 days</li>
<li>Average usage amount over last 30 days / overall average</li>
<li>Number of support tickets issued</li>
<li>Number support tickets in last 30 days / total # of support tickets</li>
<li>Max # of days without any usage</li>
<li>Current # of days without any usage / max # days without any usage</li>
</ul>
<p>However, as I said earlier, feature extraction is a very domain-specific problem so there is no guarantee that these features will be useful in your particular use case.</p>
<h3>The Class Imbalance Problem</h3>
<p>In almost all applications of this problem you will find that you have many more active accounts than cancelled accounts.  Therefore you will have many more positive training examples than negative training examples.  This is problematic because any classifier that predicts that no customers will churn will perform very well.  Consider the case where you apply the classifier to a set of 100 accounts - 90 that will not cancel in the next 2 weeks and 10 that will.  If the classifier predicts that all 100 will not cancel, it would have an accuracy of 90%.  Even though the classifier is very accurate, it is of little use because we need to identify these 10 accounts that are going to cancel.  This is called the class imbalance problem.</p>
<p>There has been a fair amount of research into this problem and survey of possible solutions can be found <a href="http://marmota.dlsi.uji.es/WebBIB/papers/2007/1_GarciaTamida2007.pdf">here</a>.  I have found that over-sampling the negative examples works well.  Specifically, I used stratified sampling on the negative examples such that my final training set contains a certain percentage of negative examples.  There is another trade-off here.  The higher the percentage of negative examples, the more false negatives (incorrectly predicting that a customer will churn) you will generate.  But if the percentage is too low, you will miss accounts that will cancel.  You must decide the threshold of false negatives that you can tolerate.</p>
<h3>Putting it All Together</h3>
<p>Now that you have defined your positive and negative examples, extracted features and dealt with the class imbalance problem, you can finally build your model.  The particular model that you choose is up to you.  I have found that random forests perform well in most applications.  The best results generally come from an ensemble of multiple models.  Obviously you would want to perform the usual train/test set splitting, cross-validation and parameter tuning that is required to reduce overfitting.  Once your model is trained up to your standards, you will apply it to your set of currently active customers.</p>
<p>You also want to decide how often to run this classifier.  Since the usage-based features are constantly changing, running the classifier frequently would be a good idea.  However, if you notice that no new accounts are being flagged, it might be a good idea to run it less frequently.  But if you have the capacity, there is really no downside to running it as often as possible.</p>
                    </article>
 
<div class="paginator">
    <div class="navButton">Page 1 / 1</div>
</div>
                </div>
            </aside><!-- /#featured -->
            
        
        <section id="extras" >
       
        
        </section><!-- /#extras -->
	
        <footer id="contentinfo" >
                <address id="about" class="vcard ">
                Proudly powered by <a href="http://getpelican.com/" target="_blank">Pelican</a>, which takes
                great advantage of <a href="http://python.org" target="_blank">Python</a>. &copy; <a class="url fn" href="http://launchyard.com">LaunchYard</a>
		
                </address><!-- /#about -->
		

                
        </footer><!-- /#contentinfo -->

<script type="text/javascript">
    var disqus_shortname = 'alexminnaar';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>